{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-12T20:46:12.945112Z",
     "start_time": "2024-05-12T20:46:12.927377Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from scipy import stats\n",
    "import alphalens\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Read data and see whether there is data missing.",
   "id": "4700cc37f9a56258"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T11:39:41.355897Z",
     "start_time": "2024-05-12T11:39:36.588932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_parquet(\"ohlcv_train_48sec.parquet.gzip\")\n",
    "print(data.info())\n",
    "print(data.columns)\n",
    "print(data.dtypes)\n",
    "print(data.isna().sum())\n",
    "print(data.head())"
   ],
   "id": "79c0b50b135a757a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 21106332 entries, (Timestamp('2022-03-01 00:01:00+0000', tz='UTC'), 'asset_1') to (Timestamp('2022-05-27 00:00:00+0000', tz='UTC'), 'asset_3')\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   Open    float64\n",
      " 1   High    float64\n",
      " 2   Low     float64\n",
      " 3   Close   float64\n",
      " 4   Volume  float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 925.3+ MB\n",
      "None\n",
      "Index(['Open', 'High', 'Low', 'Close', 'Volume'], dtype='object')\n",
      "Open      float64\n",
      "High      float64\n",
      "Low       float64\n",
      "Close     float64\n",
      "Volume    float64\n",
      "dtype: object\n",
      "Open      0\n",
      "High      0\n",
      "Low       0\n",
      "Close     0\n",
      "Volume    0\n",
      "dtype: int64\n",
      "                                      Open    High     Low   Close    Volume\n",
      "Close_time                Asset_id                                          \n",
      "2022-03-01 00:01:00+00:00 asset_1   1.5031  1.5044  1.5004  1.5007   27197.0\n",
      "2022-03-01 00:02:00+00:00 asset_1   1.5007  1.5051  1.4999  1.5044   40074.0\n",
      "2022-03-01 00:03:00+00:00 asset_1   1.5045  1.5149  1.5045  1.5132  127127.0\n",
      "2022-03-01 00:04:00+00:00 asset_1   1.5136  1.5145  1.5086  1.5086   59227.0\n",
      "2022-03-01 00:05:00+00:00 asset_1   1.5086  1.5155  1.5086  1.5127   49583.0\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Reset the multi indexes and see the data again",
   "id": "f3a5d57314df526e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T11:39:42.708176Z",
     "start_time": "2024-05-12T11:39:41.355897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = data.copy()\n",
    "df = df.reset_index()\n",
    "#datetime64[us, UTC]\n",
    "print(df.info())\n",
    "print(df.columns)\n",
    "print(df.dtypes)\n",
    "print(df.isna().sum())\n",
    "print(df.head())"
   ],
   "id": "71041119aaff9bef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21106332 entries, 0 to 21106331\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Dtype              \n",
      "---  ------      -----              \n",
      " 0   Close_time  datetime64[us, UTC]\n",
      " 1   Asset_id    object             \n",
      " 2   Open        float64            \n",
      " 3   High        float64            \n",
      " 4   Low         float64            \n",
      " 5   Close       float64            \n",
      " 6   Volume      float64            \n",
      "dtypes: datetime64[us, UTC](1), float64(5), object(1)\n",
      "memory usage: 1.1+ GB\n",
      "None\n",
      "Index(['Close_time', 'Asset_id', 'Open', 'High', 'Low', 'Close', 'Volume'], dtype='object')\n",
      "Close_time    datetime64[us, UTC]\n",
      "Asset_id                   object\n",
      "Open                      float64\n",
      "High                      float64\n",
      "Low                       float64\n",
      "Close                     float64\n",
      "Volume                    float64\n",
      "dtype: object\n",
      "Close_time    0\n",
      "Asset_id      0\n",
      "Open          0\n",
      "High          0\n",
      "Low           0\n",
      "Close         0\n",
      "Volume        0\n",
      "dtype: int64\n",
      "                 Close_time Asset_id    Open    High     Low   Close    Volume\n",
      "0 2022-03-01 00:01:00+00:00  asset_1  1.5031  1.5044  1.5004  1.5007   27197.0\n",
      "1 2022-03-01 00:02:00+00:00  asset_1  1.5007  1.5051  1.4999  1.5044   40074.0\n",
      "2 2022-03-01 00:03:00+00:00  asset_1  1.5045  1.5149  1.5045  1.5132  127127.0\n",
      "3 2022-03-01 00:04:00+00:00  asset_1  1.5136  1.5145  1.5086  1.5086   59227.0\n",
      "4 2022-03-01 00:05:00+00:00  asset_1  1.5086  1.5155  1.5086  1.5127   49583.0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Task 1: Return the 5 min return (rolling)",
   "id": "59d904adb89ef7a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T11:40:54.572378Z",
     "start_time": "2024-05-12T11:39:42.708176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "group = df.groupby('Asset_id')\n",
    "output_5min_return_rate = pd.DataFrame()\n",
    "for asset, info in group:\n",
    "    info.set_index(['Close_time'], inplace=True)\n",
    "    info['Last_Close'] = info['Close'].shift(1)\n",
    "    close_1 = info['Last_Close'].pct_change()\n",
    "    close_1.fillna(0,inplace=True)\n",
    "    close_5 = (close_1+1).rolling(window=5, min_periods=1).apply(np.prod, raw=True)-1\n",
    "    #print(type(close_5)) #<class 'pandas.core.series.Series'>\n",
    "\n",
    "    output_5min_return_rate.insert(output_5min_return_rate.shape[1], asset, close_5)  \n",
    "print(output_5min_return_rate) # task 1 ourput\n",
    "#output_5min_return_rate.to_csv(\"Answer/Task 1 Answer.csv\", mode='w')"
   ],
   "id": "b2959d7504234b31",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            asset_1  asset_10  asset_11  asset_12  \\\n",
      "Close_time                                                          \n",
      "2022-03-01 00:01:00+00:00  0.000000  0.000000  0.000000  0.000000   \n",
      "2022-03-01 00:02:00+00:00  0.000000  0.000000  0.000000  0.000000   \n",
      "2022-03-01 00:03:00+00:00  0.002466  0.000910  0.001710  0.002089   \n",
      "2022-03-01 00:04:00+00:00  0.008329  0.004725  0.007160  0.008156   \n",
      "2022-03-01 00:05:00+00:00  0.005264  0.002603  0.003282  0.004874   \n",
      "...                             ...       ...       ...       ...   \n",
      "2022-12-31 23:55:00+00:00 -0.001043 -0.002271 -0.000127 -0.000953   \n",
      "2022-12-31 23:56:00+00:00  0.000000 -0.001461  0.000151  0.000000   \n",
      "2022-12-31 23:57:00+00:00 -0.000261 -0.000853  0.000103  0.000715   \n",
      "2022-12-31 23:58:00+00:00 -0.000261 -0.000771  0.000224  0.000954   \n",
      "2022-12-31 23:59:00+00:00 -0.000522 -0.000975  0.000091  0.000716   \n",
      "\n",
      "                               asset_13  asset_14  asset_15  asset_16  \\\n",
      "Close_time                                                              \n",
      "2022-03-01 00:01:00+00:00  0.000000e+00  0.000000  0.000000  0.000000   \n",
      "2022-03-01 00:02:00+00:00  0.000000e+00  0.000000  0.000000  0.000000   \n",
      "2022-03-01 00:03:00+00:00  1.948879e-03  0.002272  0.002363  0.002428   \n",
      "2022-03-01 00:04:00+00:00  5.546811e-03  0.009512  0.009259  0.009091   \n",
      "2022-03-01 00:05:00+00:00  1.424181e-03  0.001955  0.006194  0.006023   \n",
      "...                                 ...       ...       ...       ...   \n",
      "2022-12-31 23:55:00+00:00 -9.968670e-04 -0.001391 -0.001247 -0.000401   \n",
      "2022-12-31 23:56:00+00:00 -1.424096e-04 -0.000232  0.000832 -0.000042   \n",
      "2022-12-31 23:57:00+00:00  1.424501e-04  0.000232  0.000416  0.000134   \n",
      "2022-12-31 23:58:00+00:00 -1.424501e-04  0.000000  0.000832  0.000092   \n",
      "2022-12-31 23:59:00+00:00 -1.110223e-16 -0.000232  0.000000 -0.000360   \n",
      "\n",
      "                               asset_17  asset_18  ...  asset_44  asset_45  \\\n",
      "Close_time                                         ...                       \n",
      "2022-03-01 00:01:00+00:00  0.000000e+00  0.000000  ...  0.000000  0.000000   \n",
      "2022-03-01 00:02:00+00:00  0.000000e+00  0.000000  ...  0.000000  0.000000   \n",
      "2022-03-01 00:03:00+00:00  2.627576e-03  0.005068  ...  0.005563  0.004349   \n",
      "2022-03-01 00:04:00+00:00  7.836629e-03  0.012275  ...  0.009968  0.007306   \n",
      "2022-03-01 00:05:00+00:00  6.499793e-03  0.007151  ...  0.007650  0.005392   \n",
      "...                                 ...       ...  ...       ...       ...   \n",
      "2022-12-31 23:55:00+00:00 -6.646726e-04 -0.002001  ...  0.000000 -0.001351   \n",
      "2022-12-31 23:56:00+00:00 -6.648936e-04  0.000000  ...  0.000632 -0.002027   \n",
      "2022-12-31 23:57:00+00:00  3.325574e-04 -0.000501  ...  0.000632 -0.002027   \n",
      "2022-12-31 23:58:00+00:00 -2.220446e-16  0.000501  ...  0.000000 -0.002703   \n",
      "2022-12-31 23:59:00+00:00 -2.220446e-16 -0.000501  ... -0.000632 -0.002703   \n",
      "\n",
      "                           asset_46  asset_47  asset_48   asset_5   asset_6  \\\n",
      "Close_time                                                                    \n",
      "2022-03-01 00:01:00+00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "2022-03-01 00:02:00+00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "2022-03-01 00:03:00+00:00  0.013610  0.004221 -0.001845  0.004669  0.002924   \n",
      "2022-03-01 00:04:00+00:00  0.021205  0.010641  0.001845  0.011162  0.008041   \n",
      "2022-03-01 00:05:00+00:00  0.022224  0.009586 -0.006049  0.003774  0.004873   \n",
      "...                             ...       ...       ...       ...       ...   \n",
      "2022-12-31 23:55:00+00:00 -0.000892 -0.004134 -0.001592 -0.000749  0.000000   \n",
      "2022-12-31 23:56:00+00:00 -0.000191 -0.001428  0.000000  0.000321 -0.000784   \n",
      "2022-12-31 23:57:00+00:00 -0.000701  0.000000  0.000000  0.001285  0.000000   \n",
      "2022-12-31 23:58:00+00:00 -0.000574  0.000143 -0.000797  0.000321 -0.000784   \n",
      "2022-12-31 23:59:00+00:00 -0.000574 -0.000143 -0.000797 -0.000107 -0.000784   \n",
      "\n",
      "                            asset_7   asset_8   asset_9  \n",
      "Close_time                                               \n",
      "2022-03-01 00:01:00+00:00  0.000000  0.000000  0.000000  \n",
      "2022-03-01 00:02:00+00:00  0.000000  0.000000  0.000000  \n",
      "2022-03-01 00:03:00+00:00  0.006388  0.003510  0.004271  \n",
      "2022-03-01 00:04:00+00:00  0.012420  0.010124  0.011518  \n",
      "2022-03-01 00:05:00+00:00  0.009108  0.008099  0.006952  \n",
      "...                             ...       ...       ...  \n",
      "2022-12-31 23:55:00+00:00 -0.000092  0.000604 -0.000103  \n",
      "2022-12-31 23:56:00+00:00  0.000459  0.000000  0.000723  \n",
      "2022-12-31 23:57:00+00:00  0.001194  0.000000  0.001135  \n",
      "2022-12-31 23:58:00+00:00  0.001103 -0.000604  0.001755  \n",
      "2022-12-31 23:59:00+00:00  0.000919  0.002415  0.000826  \n",
      "\n",
      "[440639 rows x 48 columns]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Task 2: Data Preprocessing with standard function",
   "id": "ccc8849ea843ec7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T11:40:54.587781Z",
     "start_time": "2024-05-12T11:40:54.574404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for continuous variables\n",
    "\n",
    "# drop columns missing rate above threshold\n",
    "def drop(data,threshold):\n",
    "    data = data[data.columns[data.isnull().mean() < threshold]]\n",
    "    \n",
    "# replace missing value with 0\n",
    "def replace0(data):\n",
    "    data = data.fillna(0)\n",
    "# replace missing value with the most frequent value of each column\n",
    "def replace0(data):\n",
    "    #Categorical imputation\n",
    "    for i in list(data):\n",
    "        data[i].fillna(data[i].value_counts().idxmax(), inplace=True)\n",
    "# replace extreme large/small values with upper/lower bound\n",
    "def extreme_MAD(data, threshold):\n",
    "    data = standardize(data)\n",
    "    median = data.quantile(0.5)\n",
    "    new_median = (abs(data-median)).quantile(0.5)\n",
    "    upper_bound = median + threshold * new_median\n",
    "    lower_bound = median - threshold * new_median\n",
    "    return data.clip(lower_bound, upper_bound, axis=1)\n",
    "        \n",
    "def identify_outliers(data, threshold):\n",
    "    data = standardize(data)\n",
    "    for i in list(data):\n",
    "        outliers = [x for x in data[i] if abs(x) > threshold]\n",
    "    print('%s has outliers (out of %s standard deviation): %s' %(i, threshold, len(outliers)))\n",
    "    \n",
    "    \n",
    "# frequency bar plot to check normal distribution\n",
    "def return_distribution(data):\n",
    "    list_bin = [-6,-5.5,-5,-4.5,-4,-3.5,-3,-2.5,-2,-1.5,-1,-0.5,0,0.5,1.0,1.5,2,2.5,3,3.5,4,4.5,5,5.5,6]\n",
    "    list_label = [ u\"(-6,-5.5]\", u\"(-5.5,-5]\", u\"(-5,-4.5]\", u\"(-4.5,-4]\", u\"(-4,-3.5]\", u\"(-3.5,-3]\", u\"(-3,-2.5]\", u\"(-2.5,-2]\", \"u(-2,-1.5]\", u\"(-1.5,-1]\", u\"(-1,-0.5]\", \n",
    "    u\"(-0.5,0]\", u\"(0,0.5]\", u\"(0.5,1]\", u\"(1,1.5]\", u\"(1.5,2]\", u\"(2,2.5]\", u\"(2.5,3]\", u\"(3,3.5]\", u\"(3.5,4]\", u\"(4,4.5]\", u\"(4.5,5)\", u\"(5,5.5]\", u\"(5.5,6)\"]\n",
    "    # for i in list(data):\n",
    "    #     #sns.boxplot(x=data[i])\n",
    "    #     data[i].plot(kind='line')\n",
    "    data = standardize(data)\n",
    "    for i in list(data):\n",
    "        a = pd.cut(data[i], list_bin, labels=list_label)\n",
    "        b = a.value_counts()\n",
    "        b1 = b.sort_index()\n",
    "        c = {'section': b1.index, 'frequency': b1.values}\n",
    "        e = pd.DataFrame(c)\n",
    "        ax = plt.figure(figsize=(20,15)).add_subplot(111)\n",
    "        sns.barplot(x='section', y='frequency', data = e)\n",
    "        #ax.set_ylim([0,30])\n",
    "        ax.set_xlabel('z-score interval', fontsize=20)\n",
    "        ax.set_ylabel('frequency', fontsize=20)\n",
    "        ax.set_title('frequency plot of %s'%i, size=40)\n",
    "        \n",
    "        for x,y in zip(range(len(e)), e.frequency):\n",
    "            ax.text(x,y, '%d'%y, ha='center', va='bottom', fontsize=30, color='grey')\n",
    "        #plt.savefig('/figure/frequency plot of %s'%i, bbox_inches =\"tight\")\n",
    "\n",
    "# box_plots to check out liner point\n",
    "def box_plot(data):\n",
    "    for i in list(data):\n",
    "        sns.boxplot(x=data[i])\n",
    "       \n",
    "# non-dimensionalization to 0-1\n",
    "def zero_to_one(data):\n",
    "    output_01 = pd.DataFrame()\n",
    "    for i in list(data):\n",
    "        output_01[i] = (data[i] - np.min(data[i]) ) / (np.max(data[i]) - np.min(data[i]) )\n",
    "    return output_01\n",
    "\n",
    "# normalization to z-score\n",
    "def standardize(data):\n",
    "    output_standard = pd.DataFrame()\n",
    "    for i in list(data):\n",
    "        output_standard[i] = (data[i] - np.mean(data[i])) / np.std(data[i])\n",
    "    return output_standard\n",
    "        \n",
    "#print(output_5min_return_rate.head())\n",
    "#print(zero_to_one(output_5min_return_rate).head())\n",
    "#print(standardize(output_5min_return_rate).head())\n",
    "#return_distribution(output_5min_return_rate)\n",
    "#box_plot(standardize(output_5min_return_rate))\n",
    "#return_distribution(extreme_MAD(output_5min_return_rate,12))"
   ],
   "id": "25c11725fdca13e5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Task 3: IC (Information Coeffieient), IR (Information Ratio)\n",
    "Pearson Correlation: suit for normal distribution, linear \n",
    "Spearman Correlation: suit for non-normal distribuition, nonlinear, robust\n",
    "\n",
    "Normal IC: $IC_{i}$ = Pearson(predict return calculated by $factor_i$ at time t-1, actural return at time t)\n",
    "\n",
    "Rank IC: $Rank~IC_{i}$ = Spearman(the rank of predict return calculated by $factor_i$ at time t, the rank of actural return at time t+1)\n",
    "\n",
    "IR: Average Rank IC among different time period/ standard deviation of Rank IC among different time period\n",
    "\n",
    "$\\rho \\left( r^{t},f^{t-1} \\right) \n",
    "= \\frac{Cov\\left( r^{t},f^{t-1}\\right)} {\\sqrt{Var\\left(r^{t}\\right)} \\cdot \\sqrt{Var\\left(f^{t-1} \\right)}}\n",
    "=\\frac{\\sum\\limits_{i=1}^{N}{\\left( r_{i}^{t}-\\bar{r}^{t} \\right)\\left( f_{i}^{t-1}-\\bar{f}^{t-1} \\right)}}{\\sqrt{\\sum\\limits_{i=1}^{N}{{{\\left( r_{i}^{t}-\\bar{r}^{t} \\right)}^{2}}}\\cdot \\sum\\limits_{i=1}^{N}{{{\\left( f_{i}^{t-1}-\\bar{f}^{t-1} \\right)}^{2}}}}}$"
   ],
   "id": "64e863bd79153deb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T21:54:18.839462Z",
     "start_time": "2024-05-12T21:54:18.814457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "period_list = [1, 2, 3, 7, 15, 30]\n",
    "factor_list = ['MA','Momentum_Close','Momentum_Volume','std_Close_to_Open', 'corr_Close_to_Volume']\n",
    "\n",
    "def cal_factor(df,factor_name):\n",
    "    if factor_name == 'MA':\n",
    "        df['MA'] = df['Close'].shift(1).rolling(window=5, min_periods=1).mean()\n",
    "        df['MA'] = df['MA'].fillna(0)\n",
    "        # return df['MA']\n",
    "    if factor_name == 'Momentum_Close':\n",
    "        # Momentum\n",
    "        df['Momentum_Close'] = (df['Close'].shift(1) - df['Close'].shift(2))/df['Close'].shift(2)\n",
    "        df['Momentum_Close'] = df['Momentum_Close'].fillna(0)\n",
    "        # return df['Momentum']\n",
    "    if factor_name == 'Momentum_Volume':\n",
    "        df['Momentum_Volume'] = (df['Volume'].shift(1) - df['Volume'].shift(2))/df['Volume'].shift(2)\n",
    "        df['Momentum_Volume'] = df['Momentum_Volume'].fillna(0)\n",
    "        # return df['open_volume']\n",
    "    if factor_name == 'std_Close_to_Open':\n",
    "        df['std_Close_to_Open'] = (df['Close']/df['Open']).shift(1).std()\n",
    "        df['std_Close_to_Open'] = df['std_Close_to_Open'].fillna(0)\n",
    "    if factor_name == 'corr_Close_to_Volume':\n",
    "        df['corr_Close_to_Volume'] = df['Close'].shift(5).corr(df['Volume'].shift(1))\n",
    "        df['corr_Close_to_Volume'] = df['corr_Close_to_Volume'].fillna(0)\n",
    "    if factor_name == 'Volume':\n",
    "        df['Volume_1'] = df['Volume'].shift(1)\n",
    "        df['Volume_1'] = df['Volume'].fillna(0)\n",
    "        # return df['Volume']\n",
    "    \n",
    "\n",
    "def IC_data(period, df, factor_name):  \n",
    "    group = df.groupby(\"Asset_id\")\n",
    "    day_return_rate = pd.DataFrame()\n",
    "    factor = pd.DataFrame()\n",
    "   \n",
    "    for asset, info in group:\n",
    "        ohlcv_dict = {\n",
    "            'Open':'first',\n",
    "            'High':'max',\n",
    "            'Low':'min',\n",
    "            'Close':'last',\n",
    "            'Volume':'sum'\n",
    "        }\n",
    "        info.set_index(['Close_time'], inplace=True)\n",
    "        info = info.resample('1d').agg(ohlcv_dict)\n",
    "        #print(info)\n",
    "        daily = info.copy()\n",
    "        daily = daily.reset_index(drop=False)\n",
    "        daily['Close_time'] = pd.DatetimeIndex(daily['Close_time']).date\n",
    "        daily = daily.set_index('Close_time')\n",
    "        daily['Asset_id'] = asset\n",
    "\n",
    "        \n",
    "        daily['Close_period'] = daily['Close'].shift(int(period))\n",
    "        close_period = daily['Close_period'].pct_change()\n",
    "        close_period.fillna(0,inplace=True) # <class 'pandas.core.series.Series'>\n",
    "        \n",
    "        cal_factor(daily,factor_name)\n",
    "        #print(daily)\n",
    "        factor_value = daily.iloc[:,-1]\n",
    "    \n",
    "        day_return_rate.insert(day_return_rate.shape[1], asset, close_period) \n",
    "        \n",
    "        factor.insert(factor.shape[1], asset, factor_value)\n",
    "            \n",
    "    return(day_return_rate, factor)\n"
   ],
   "id": "19f425ddb43648d4",
   "outputs": [],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T21:55:14.451956Z",
     "start_time": "2024-05-12T21:54:44.909479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#alphalens is out of maintain. I can't call it anyway.\n",
    "# factor_return = alphalens.utils.get_clean_factor_and_forward_returns(factor_alphalens['Volume'].shift(48), price_alphalens, quantiles=5, periods=(1,5,10))\n",
    "\n",
    "def normal_IC(day_return_rate, factor):\n",
    "    df = pd.DataFrame()\n",
    "    temp = day_return_rate.copy()\n",
    "    temp = temp.reset_index(drop=False)\n",
    "    df['Close_time'] = temp['Close_time']\n",
    "    #df.set_index('Close_time', inplace=True)\n",
    "    df['IC'] = 0\n",
    "    for i in range(day_return_rate.shape[0]):   \n",
    "        df.loc[i,'IC'] = np.corrcoef(np.asarray(factor.iloc[i,:][~np.isnan(factor.iloc[i,:])]), np.asarray(day_return_rate.iloc[i,:][~np.isnan(day_return_rate.iloc[i,:])]))[1][0]     \n",
    "    df = df.set_index(['Close_time'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def rank_IC(day_return_rate, factor):\n",
    "    df = pd.DataFrame()\n",
    "    temp = day_return_rate.copy()\n",
    "    temp = temp.reset_index(drop=False)\n",
    "    df['Close_time'] = temp['Close_time']\n",
    "    df['Rank_IC'] = 0\n",
    "    for i in range(day_return_rate.shape[0]):\n",
    "        # print(np.asarray(factor.iloc[i,:][~np.isnan(factor.iloc[i,:])]))\n",
    "        # print(np.asarray(day_return_rate.iloc[i,:][~np.isnan(day_return_rate.iloc[i,:])]))\n",
    "\n",
    "        df.loc[i,'Rank_IC'] = stats.pearsonr(np.asarray(factor.iloc[i,:][~np.isnan(factor.iloc[i,:])]), np.asarray(day_return_rate.iloc[i,:][~np.isnan(day_return_rate.iloc[i,:])])).statistic\n",
    "        # np.isnan    pd.isnull\n",
    "    df = df.set_index(['Close_time'])\n",
    "    return df\n",
    "\n",
    "period_list = [1, 2, 3, 7, 15, 30]\n",
    "def IR(period_list, factor_name):\n",
    "    muti_IC = pd.DataFrame()\n",
    "    for period in period_list:\n",
    "        day_return_rate, factor = IC_data(period, input, factor_name)\n",
    "        if period == 1:\n",
    "            temp = day_return_rate.copy()\n",
    "            temp = temp.reset_index(drop=False)\n",
    "            muti_IC['Close_time'] = temp['Close_time']\n",
    "            muti_IC = muti_IC.set_index('Close_time', drop=True)  \n",
    "        temp = rank_IC(day_return_rate, factor).copy()\n",
    "        temp = temp['Rank_IC']\n",
    "        #muti_IC = muti_IC.insert(muti_IC.shape[1], period, temp)\n",
    "        muti_IC = pd.merge(muti_IC, temp, on='Close_time')\n",
    "        muti_IC.rename(columns={'Rank_IC':'%s_days'%period}, inplace=True)\n",
    "    return muti_IC\n",
    "input = data.copy()\n",
    "input = df.reset_index()\n",
    "muti_IC = IR(period_list, factor_name='Volume')"
   ],
   "id": "64a191666b21f581",
   "outputs": [],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T21:56:04.874700Z",
     "start_time": "2024-05-12T21:56:04.857698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(muti_IC)\n",
    "a = muti_IC.mean(axis=0)\n",
    "b = muti_IC.std(axis=0)\n",
    "print('各周期RankIC均值: %s' %a)\n",
    "print('各周期RankIC标准差: %s' %b)\n",
    "c = a.mean()\n",
    "d = a.std()\n",
    "e = c/d\n",
    "print('IC:%s, IR:%s'%(c,e))"
   ],
   "id": "768a2112046bb948",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              1_days    2_days    3_days    7_days   15_days   30_days\n",
      "Close_time                                                            \n",
      "2022-03-01       NaN       NaN       NaN       NaN       NaN       NaN\n",
      "2022-03-02       NaN       NaN       NaN       NaN       NaN       NaN\n",
      "2022-03-03 -0.179515       NaN       NaN       NaN       NaN       NaN\n",
      "2022-03-04 -0.059367 -0.178987       NaN       NaN       NaN       NaN\n",
      "2022-03-05  0.084681 -0.051269 -0.178502       NaN       NaN       NaN\n",
      "...              ...       ...       ...       ...       ...       ...\n",
      "2022-12-27 -0.069254 -0.246634  0.036013 -0.019574 -0.032484  0.497996\n",
      "2022-12-28 -0.086496 -0.119359 -0.236649 -0.264511  0.000152 -0.075546\n",
      "2022-12-29 -0.017240 -0.058493 -0.086018  0.047076 -0.167681 -0.011484\n",
      "2022-12-30  0.154508 -0.043678 -0.107260 -0.091251  0.086178 -0.116588\n",
      "2022-12-31 -0.032171  0.075289 -0.057344 -0.033533 -0.003837 -0.294316\n",
      "\n",
      "[306 rows x 6 columns]\n",
      "各周期RankIC均值: 1_days     0.054956\n",
      "2_days     0.026607\n",
      "3_days     0.024713\n",
      "7_days     0.022164\n",
      "15_days    0.007218\n",
      "30_days    0.007675\n",
      "dtype: float64\n",
      "各周期RankIC标准差: 1_days     0.273052\n",
      "2_days     0.246310\n",
      "3_days     0.238000\n",
      "7_days     0.219047\n",
      "15_days    0.199831\n",
      "30_days    0.195625\n",
      "dtype: float64\n",
      "IC:0.02388886465091138, IR:1.371472468920382\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Task 4",
   "id": "f2c4d876c9bb1b4c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "https://www.ricequant.com/doc/rqdata/python/factors-dictionary.html#%E5%9D%87%E7%BA%BF%E7%B1%BB%E6%8C%87%E6%A0%87\n",
    "\n",
    "Size\n",
    "Momentum \n",
    "\n",
    "(Return_rate_1day, Return_rate_3day, Return_rate_7day, Return_rate_15day)\n",
    "\n",
    "Volume \n",
    "\n",
    "(log_volume, log_price*volume, log_price*volume/turnover_rate, )\n",
    "\n",
    "Volatility\n",
    "\n",
    "(std_close_open)"
   ],
   "id": "6117e3570a29d919"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T21:59:55.217887Z",
     "start_time": "2024-05-12T21:57:50.236811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "period_list = [1, 2, 3, 7, 15, 30]\n",
    "factor_list = ['MA','Momentum_Close','Momentum_Volume','std_Close_to_Open', 'corr_Close_to_Volume']\n",
    "\n",
    "for factor_name in factor_list:\n",
    "\n",
    "    muti_IC = IR(period_list, factor_name)\n",
    "    #print(muti_IC)\n",
    "    a = muti_IC.mean(axis=0)\n",
    "    b = muti_IC.std(axis=0)\n",
    "    c = a.mean()\n",
    "    d = a.std()\n",
    "    e = c/d\n",
    "    print('factor_%s ,IC:%s, IR:%s'%(factor_name,c,e))\n",
    "\n",
    "\n"
   ],
   "id": "1d1daf992158e006",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factor_MA ,IC:0.00976411285335221, IR:5.939543849763861\n",
      "factor_Momentum_Close ,IC:0.16112571807109644, IR:0.39177783379310355\n",
      "factor_Momentum_Volume ,IC:0.05181719822092463, IR:0.26539625806273426\n",
      "factor_std_Close_to_Open ,IC:-0.022892180404016072, IR:-4.113783399588695\n",
      "factor_corr_Close_to_Volume ,IC:0.0017140867742168034, IR:0.7972066113588716\n"
     ]
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Appendix",
   "id": "a25194a3ebd8bf16"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "有待改进：\n",
    "1 没有找到rank_IC > 0.05 且 IR > 0.5的因子。可以考虑采用多因子模型，主成分分析法，筛选出一系列得分高且不太相关的因子 进行组合。\n",
    "2 代码框架乱，函数封装得不好"
   ],
   "id": "edbe732d870b2803"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Resampled data",
   "id": "4c2d67398ee7f249"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# path2 = 'data5min'\n",
    "# os.makedirs(path2, exist_ok=True)  \n",
    "# files1 = [f for f in os.listdir(path1) if f.endswith('.csv')]\n",
    "# for file in files1:\n",
    "#     file_path = os.path.join(path1, file)\n",
    "#     df = pd.read_csv(file_path, parse_dates=['Close_time'], index_col=['Close_time'])\n",
    "#     \n",
    "#     df['Open'] = df['Open'].resample('5min').first()\n",
    "#     df['High'] = df['High'].resample('5min').max()\n",
    "#     df['Low'] = df['Low'].resample('5min').min()\n",
    "#     df['Close'] = df['Close'].resample('5min').last()\n",
    "#     df['Volume'] = df['Volume'].resample('5min').sum()\n",
    "#     df = df.resample('5min').last()\n",
    "#     asset = df['Asset_id'].iloc[0]\n",
    "#     # print(df)\n",
    "#     # print(asset)\n",
    "#     # print(df.head())\n",
    "#     # print(df.tail())\n",
    "#     df.to_csv(\"%s/%s.csv\"% (path2,asset), index=True, mode='w')\n",
    "#     "
   ],
   "id": "603be96c9de353e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# files2 = [f for f in os.listdir(path2) if f.endswith('.csv')]\n",
    "# for file in files2:\n",
    "#     file_path = os.path.join(path2, file)\n",
    "#     df = pd.read_csv(file_path, parse_dates=['Close_time'], index_col=['Close_time'])\n",
    "#     df['LastClose'] = df['Close'].shift(1)\n",
    "#     # num = float(df['Open'].iloc[0].copy())\n",
    "#     # df.loc[0, \"LastClose\"] = num\n",
    "#     # df['LastClose'].iloc[0] = df['Open'].iloc[0]\n",
    "#     close_5 = df['LastClose'].pct_change()\n",
    "#     close_5.fillna(0,inplace=True)\n",
    "#     print(close_5.head())\n",
    "# \n",
    "#     #df.to_csv(\"%s/%s.csv\"% (path2,asset), index=True, mode='w')"
   ],
   "id": "312abf17577c2d12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "IC rankIC IR",
   "id": "9316a31ef592b723",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# group = df.groupby(\"Asset_id\")\n",
    "# day_return_rate = pd.DataFrame()\n",
    "# factor = pd.DataFrame()\n",
    "# factor_alphalens = pd.DataFrame()\n",
    "# price_alphalens = pd.DataFrame()\n",
    "# #period_list = {1, 2, 3, 7, 15, 30}\n",
    "# \n",
    "# for asset, info in group:\n",
    "#     ohlcv_dict = {\n",
    "#         'Open':'first',\n",
    "#         'High':'max',\n",
    "#         'Low':'min',\n",
    "#         'Close':'last',\n",
    "#         'Volume':'sum'\n",
    "#     }\n",
    "#     info.set_index(['Close_time'], inplace=True)\n",
    "#     info = info.resample('1d').agg(ohlcv_dict)\n",
    "#     #print(info)\n",
    "#     daily = info.copy()\n",
    "#     daily = daily.reset_index(drop=False)\n",
    "#     daily['Close_time'] = pd.DatetimeIndex(daily['Close_time']).date\n",
    "#     daily = daily.set_index('Close_time')\n",
    "#     daily['Asset_id'] = asset\n",
    "#     #print(daily)\n",
    "# \n",
    "# \n",
    "#     daily['Last_Close'] = daily['Close'].shift(1)\n",
    "#     close_period = daily['Close'].pct_change()\n",
    "#     close_period.fillna(0,inplace=True) # <class 'pandas.core.series.Series'>\n",
    "# \n",
    "#     close = daily['Close'] # <class 'pandas.core.series.Series'>\n",
    "#     factor_value = daily['Volume']\n",
    "# \n",
    "#     day_return_rate.insert(day_return_rate.shape[1], asset, close_period) \n",
    "# \n",
    "#     factor.insert(factor.shape[1], asset, factor_value)\n",
    "# \n",
    "#     factor_alphalens = pd.concat([factor_alphalens, daily[['Asset_id','Volume']]], axis=0)\n",
    "# \n",
    "#     price_alphalens.insert(price_alphalens.shape[1], asset, close)\n",
    "# #\n",
    "# factor_alphalens = factor_alphalens.reset_index(drop=False)\n",
    "# factor_alphalens.index = pd.to_datetime(factor_alphalens['Close_time'])\n",
    "# factor_alphalens = factor_alphalens.drop(factor_alphalens.columns[[0]], axis=1)\n",
    "# factor_alphalens.index.name = None\n",
    "# factor_alphalens.sort_index(inplace=True)\n",
    "# factor_alphalens = factor_alphalens.set_index([factor_alphalens.index, factor_alphalens['Asset_id']], drop = True)\n",
    "# factor_alphalens = factor_alphalens.drop(factor_alphalens.columns[[0]], axis=1)\n",
    "# factor_alphalens.sort_index(inplace=True)\n",
    "# factor_alphalens.index.name = None\n",
    "# \n",
    "# \n",
    "# # factor_alphalens = factor_alphalens.groupby(['Close_time', 'Asset_id']).mean()\n",
    "# \n",
    "# # factor_alphalens = factor_alphalens.reset_index(drop=False)\n",
    "# # factor_alphalens = factor_alphalens.groupby(['Close_time']).apply(lambda x: x[:])\n",
    "# # factor_alphalens = factor_alphalens.drop(factor_alphalens.columns[[0]], axis=1)\n",
    "# # factor_alphalens = factor_alphalens.reset_index(drop=False)\n",
    "# # factor_alphalens = factor_alphalens.drop(factor_alphalens.columns[[1]], axis=1)\n",
    "# # factor_alphalens = factor_alphalens.set_index(['Close_time', 'Asset_id'], inplace =False)\n",
    "# \n",
    "# print(day_return_rate) \n",
    "# print(factor)\n",
    "# \n",
    "# # print(factor_alphalens)\n",
    "# # print(price_alphalens)"
   ],
   "id": "1f7db9da29445d4c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
